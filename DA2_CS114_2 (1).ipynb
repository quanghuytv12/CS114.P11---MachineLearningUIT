{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj1VTVchgTw3"
      },
      "source": [
        "#IMPORT LIBRARY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjV_--_nWqGf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "from IPython.display import display\n",
        "from pandas.plotting import scatter_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, StratifiedKFold, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler, RobustScaler, QuantileTransformer, PowerTransformer\n",
        "from sklearn.linear_model import LinearRegression,  Lasso, Ridge, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.base import BaseEstimator, RegressorMixin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDy_egCFgaFE"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00BvHQXSglRX"
      },
      "source": [
        "# Data Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y49LTYQ_hUtG"
      },
      "source": [
        "## 1. Load Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtBdpt_Lguv6"
      },
      "outputs": [],
      "source": [
        "root_dir = \"/content/drive/MyDrive/dataset\"\n",
        "df_th = pd.read_csv(os.path.join(root_dir,'th-public.csv'))\n",
        "df_tbtl = pd.read_csv(os.path.join(root_dir,'tbtl-public.csv'))\n",
        "df_ck = pd.read_csv(os.path.join(root_dir,'ck-public.csv'))\n",
        "df_qt = pd.read_csv(os.path.join(root_dir,'qt-public.csv'))\n",
        "anno_df = pd.read_csv(os.path.join(root_dir,'annonimized.csv'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RytILu7Hhar2"
      },
      "source": [
        "## 2. Handle missing value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYBcxY8JhfJO"
      },
      "outputs": [],
      "source": [
        "df_th.dropna(subset=['TH'], inplace=True)\n",
        "df_tbtl.dropna(subset=['TBTL'], inplace=True)\n",
        "df_ck.dropna(subset=['CK'], inplace=True)\n",
        "df_qt.dropna(subset=['diemqt'], inplace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-xsKTBhhnKZ"
      },
      "source": [
        "##3. Overview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BDR1Br5mh8Rm"
      },
      "outputs": [],
      "source": [
        "def overview(df):\n",
        "    df.info()\n",
        "    df.describe()\n",
        "    df.dtypes\n",
        "    print(df.nunique())\n",
        "    df.shape\n",
        "\n",
        "overview(anno_df)\n",
        "overview(df_th)\n",
        "overview(df_tbtl)\n",
        "overview(df_ck)\n",
        "overview(df_qt)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxkk9eNpi8Uk"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "OvxV3Y_YkLFk"
      },
      "outputs": [],
      "source": [
        "display(anno_df.head(5))\n",
        "display(df_tbtl.head(5))\n",
        "display(df_qt.head(5))\n",
        "display(df_th.head(5))\n",
        "display(df_ck.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWDhHCG7m8OO"
      },
      "outputs": [],
      "source": [
        "rename_dict = {\n",
        "    \"concat('it001',`assignment_id`)\": \"assignment_id\",\n",
        "    \"concat('it001',`problem_id`)\": \"problem_id\",\n",
        "    \"concat('it001', username)\": \"username\",\n",
        "    \"concat('it001',`language_id`)\": \"language_id\"\n",
        "}\n",
        "\n",
        "anno_df.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "df_tbtl.rename(columns={\"username\": \"username\"}, inplace=True)\n",
        "df_th.rename(columns={\"hash\": \"username\"}, inplace=True)\n",
        "df_qt.rename(columns={\"hash\": \"username\"}, inplace=True)\n",
        "df_ck.rename(columns={\"hash\": \"username\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JOWg32v1n3Cg"
      },
      "outputs": [],
      "source": [
        "display(anno_df.head(5))\n",
        "display(df_tbtl.head(5))\n",
        "display(df_qt.head(5))\n",
        "display(df_th.head(5))\n",
        "display(df_ck.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT7LMt8poQx0"
      },
      "source": [
        "#Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hj23TGp3obnZ"
      },
      "source": [
        "##1. Feature phản ánh độ chính xác\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSgUrhg6obd-"
      },
      "outputs": [],
      "source": [
        "#Sub = submission (lần nộp bài)\n",
        "#Problem (bài tập nhỏ/ có nhiều problem trong 1 assignment)\n",
        "#Assignment (bài tập lớn/ 1 bài tập lớn có nhiều problem)\n",
        "\n",
        "#Tính số lần bài nộp được chấm đúng (xanh) của từng sinh viên:\n",
        "right_sub = anno_df[(anno_df['is_final'] == 1) & (anno_df['pre_score'] == 10000)]\n",
        "right_sub_count = right_sub.groupby('username').size().reset_index(name='right_sub_count')\n",
        "\n",
        "#Tính số problem được chấm đúng của từng sinh viên:\n",
        "right_pro_count = right_sub.groupby('username')['problem_id'].nunique().reset_index(name='right_pro_count')\n",
        "\n",
        "#Tính số assignment được chấm đúng của từng sinh viên:\n",
        "right_ass_count = right_sub.groupby('username')['assignment_id'].nunique().reset_index(name='right_ass_count')\n",
        "\n",
        "#Đưa vào dataframe\n",
        "anno_df = anno_df.merge(right_sub_count, on='username', how='left')\n",
        "anno_df = anno_df.merge(right_pro_count, on='username', how='left')\n",
        "anno_df = anno_df.merge(right_ass_count, on='username', how='left')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBbKj8QnudWs"
      },
      "outputs": [],
      "source": [
        "#Xử lý giá trị thiếu\n",
        "anno_df['right_sub_count'] = anno_df['right_sub_count'].fillna(0).astype(float)\n",
        "anno_df['right_pro_count'] = anno_df['right_pro_count'].fillna(0).astype(float)\n",
        "anno_df['right_ass_count'] = anno_df['right_ass_count'].fillna(0).astype(float)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBCuE77VvgSx"
      },
      "outputs": [],
      "source": [
        "#Tính số lần nộp bài (submission count)\n",
        "sub_count = anno_df.groupby('username').size().reset_index(name = 'sub_count')\n",
        "\n",
        "#Tính số assignment mà sinh viên có làm (đúng và sai)\n",
        "ass_count = anno_df.groupby('username')['assignment_id'].nunique().reset_index(name = 'ass_count')\n",
        "\n",
        "#Tính số problem mà sinh viên có làm\n",
        "pro_count = anno_df.groupby('username')['problem_id'].nunique().reset_index(name = 'pro_count')\n",
        "\n",
        "#Thêm vào dataframe\n",
        "anno_df = anno_df.merge(sub_count, on='username', how='left')\n",
        "anno_df = anno_df.merge(ass_count, on='username', how='left')\n",
        "anno_df = anno_df.merge(pro_count, on='username', how='left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E28dKu0nwNP6"
      },
      "outputs": [],
      "source": [
        "right_sub = anno_df[(anno_df['is_final'] == 1) & (anno_df['pre_score'] == 10000)]\n",
        "right_sub = right_sub.drop_duplicates(subset=['username', 'problem_id'], keep=\"first\")\n",
        "\n",
        "right_sub['score'] = (right_sub['pre_score'] / 10000) * (right_sub['coefficient'] / 100)\n",
        "total_scores = right_sub.groupby('username')['score'].sum().reset_index(name='total_score')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZGSUV3k0uMa"
      },
      "outputs": [],
      "source": [
        "anno_df = anno_df.merge(total_scores, on='username', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiMyErTj0vQq"
      },
      "outputs": [],
      "source": [
        "anno_df['total_score'] = anno_df['total_score'].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0VTnLtT5LBm"
      },
      "outputs": [],
      "source": [
        "status_dummies = pd.get_dummies(anno_df['status'], prefix='status_')\n",
        "df_expanded = pd.concat([anno_df, status_dummies], axis=1)\n",
        "df_grouped = df_expanded.groupby('username')[status_dummies.columns].sum().reset_index()\n",
        "anno_df = anno_df.merge(df_grouped, on='username', how='left')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lk22da_P-OTM"
      },
      "outputs": [],
      "source": [
        "del df_expanded, df_grouped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2PHidoH_C_S"
      },
      "outputs": [],
      "source": [
        "#Tính tỉ lệ submit đúng so với tổng số lần submit\n",
        "anno_df['right_sub_rate'] =anno_df[\"right_sub_count\"] / anno_df[\"sub_count\"] * 100\n",
        "#Tính tỉ lệ problem đúng so với tổng problem tham gia\n",
        "anno_df['right_pro_rate'] = anno_df[\"right_pro_count\"] / anno_df[\"pro_count\"] * 100\n",
        "#Tính tỉ lệ problem đúng so với tổng số lần submit\n",
        "anno_df[\"right_pro_sub_rate\"] = anno_df[\"right_pro_count\"] / anno_df[\"sub_count\"] * 100\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Feature phản ánh độ siêng năng"
      ],
      "metadata": {
        "id": "A7gz8eYpOtai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Chuyển đổi giá trị về dạng date time\n",
        "anno_df['submission_date'] = pd.to_datetime(anno_df['created_at'], format='%m-%d %H:%M:%S', errors='coerce')\n",
        "anno_df['submission_week'] = anno_df['submission_date'].dt.isocalendar().week\n"
      ],
      "metadata": {
        "id": "2D_j-uOmMZCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo một cột ngày duy nhất từ 'submission_date'\n",
        "anno_df['submission_day'] = anno_df['submission_date'].dt.date\n",
        "\n",
        "# Tính số ngày làm bài\n",
        "active_days = anno_df.groupby('username')['submission_day'].nunique().reset_index(name='active_days')"
      ],
      "metadata": {
        "id": "1_o6SEZdvCr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính tỉ lệ làm bài hàng ngày\n",
        "sub_count = anno_df.groupby('username').size().reset_index(name='sub_count')\n",
        "\n",
        "daily_submission_rate = pd.merge(sub_count, active_days, on='username', how='left')\n",
        "daily_submission_rate['daily_submission_rate'] = daily_submission_rate['sub_count'] / daily_submission_rate['active_days']\n",
        "\n"
      ],
      "metadata": {
        "id": "u16A_8TpvI1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Số lần cải thiện điểm số\n",
        "anno_df['score_improved'] = anno_df.groupby('username')['pre_score'].diff().apply(lambda x: 1 if x > 0 else 0)\n",
        "improvements = anno_df.groupby('username')['score_improved'].sum().reset_index(name='improvement_count')\n",
        "anno_df.drop(columns=['sub_count'], inplace=True)"
      ],
      "metadata": {
        "id": "u84x0aj3uLWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tổng hợp các đặc trưng về độ siêng năng\n",
        "diligence_features = pd.merge(active_days, sub_count, on='username', how='left')\n",
        "diligence_features = pd.merge(diligence_features, daily_submission_rate[['username', 'daily_submission_rate']], on='username', how='left')\n",
        "diligence_features = pd.merge(diligence_features, improvements, on='username', how='left')\n",
        "\n",
        "# Điền giá trị thiếu\n",
        "diligence_features.fillna(0, inplace=True)\n",
        "\n",
        "diligence_features"
      ],
      "metadata": {
        "id": "GBVr9UvlvS9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anno_df = pd.merge(anno_df, diligence_features, on='username', how='left')"
      ],
      "metadata": {
        "id": "830vdRqk7JBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anno_df"
      ],
      "metadata": {
        "id": "4S80IvfsKp-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Feature phản ảnh số lượng bài khó mà sinh viên giải"
      ],
      "metadata": {
        "id": "mINAByfexUcW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "SuYlzJ9gIIPO"
      },
      "outputs": [],
      "source": [
        "assignments_per_problem = anno_df.groupby('problem_id')['assignment_id'].unique()\n",
        "assignments_per_problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "pdl651UbImmh"
      },
      "outputs": [],
      "source": [
        "assignments_per_problem = anno_df.groupby('problem_id')['assignment_id'].unique()\n",
        "students_per_assignment = anno_df.groupby('assignment_id')['username'].nunique()\n",
        "students_per_problem = assignments_per_problem.apply(lambda x: students_per_assignment.loc[x].sum())\n",
        "final_solutions = anno_df[(anno_df['is_final'] == 1) & (anno_df['pre_score'] == 10000)]\n",
        "solved_counts = final_solutions.groupby('problem_id')['username'].nunique()\n",
        "solved_ratio = (solved_counts / students_per_problem * 100).fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3u7f0lLIw0_"
      },
      "outputs": [],
      "source": [
        "lv_df = pd.DataFrame({\n",
        "    'problem_id': students_per_problem.index,\n",
        "    'participated': students_per_problem.values,\n",
        "    'solved': solved_counts.reindex(students_per_problem.index, fill_value=0).values,\n",
        "    'ratio_solved/participated': solved_ratio.values\n",
        "})\n",
        "lv_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "_LJgKTgcJz0e"
      },
      "outputs": [],
      "source": [
        "lv_df_sorted = lv_df.sort_values(by='ratio_solved/participated', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(range(len(lv_df_sorted)), lv_df_sorted['ratio_solved/participated'], color='red')\n",
        "plt.xlabel('problem index')\n",
        "plt.ylabel('Tỉ lệ')\n",
        "plt.title('Tỉ lệ sinh viên giải được trên tổng số sinh viên tham gia mỗi problem')\n",
        "plt.xticks(rotation=90)\n",
        "plt.yticks(range(0, 101, 5))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRQhNhRIL0ES"
      },
      "outputs": [],
      "source": [
        "def classify_ratio(ratio):\n",
        "    if ratio >= 60:\n",
        "        return 'level_1'\n",
        "    elif 35 <= ratio < 60:\n",
        "        return 'level_2'\n",
        "    elif 20 <= ratio < 35:\n",
        "        return 'level_3'\n",
        "    elif 10 <= ratio < 20:\n",
        "        return 'level_4'\n",
        "    else:\n",
        "        return 'level_5'\n",
        "\n",
        "# Tạo cột mới 'level' dựa trên các giá trị của cột 'ratio_solved/participated'\n",
        "lv_df['level'] = lv_df['ratio_solved/participated'].apply(classify_ratio)\n",
        "lv_df.to_csv('lv.csv', index=False)\n",
        "display(lv_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anno_df.info()"
      ],
      "metadata": {
        "id": "kVVM6s8jCEGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCavS-WgNiVn"
      },
      "outputs": [],
      "source": [
        "anno_df = pd.merge(anno_df, lv_df[['problem_id', 'level']], on='problem_id', how='left')\n",
        "ac_submissions = anno_df[(anno_df['is_final'] == 1) & (anno_df['pre_score'] == 10000)]\n",
        "level_counts = ac_submissions.groupby(['username', 'level']).size().unstack(fill_value=0).reset_index()\n",
        "anno_df = pd.merge(anno_df, level_counts, on='username', how='left')\n",
        "\n",
        "level_columns = ['level_1', 'level_2', 'level_3', 'level_4', 'level_5']\n",
        "\n",
        "for column in level_columns:\n",
        "    anno_df[column] = anno_df[column].fillna(0).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "anno_df.info()"
      ],
      "metadata": {
        "id": "_Wifey2AL6ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krWGknG3N4WF",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "anno_df['problem_id'] = anno_df['problem_id'].str.strip()\n",
        "# Thực hiện fit_transform trên cột 'assignment_id'\n",
        "encoded_columns = encoder.fit_transform(anno_df[['problem_id']])\n",
        "# Lấy tên các cột sau khi encoding và thêm tiền tố 'in__'\n",
        "encoded_column_names = ['in__' + cat for cat in encoder.categories_[0]]\n",
        "# Tạo DataFrame cho các cột đã được One-Hot Encoded\n",
        "encoded_df = pd.DataFrame(encoded_columns, columns=encoded_column_names)\n",
        "# Kết hợp DataFrame ban đầu với các cột mới\n",
        "anno_df = pd.concat([anno_df, encoded_df], axis=1)\n",
        "\n",
        "encoder3 = OneHotEncoder(sparse_output=False)\n",
        "anno_df['assignment_id'] = anno_df['assignment_id'].str.strip()\n",
        "# Thực hiện fit_transform trên cột 'assignment_id'\n",
        "encoded3_columns = encoder3.fit_transform(anno_df[['assignment_id']])\n",
        "# Lấy tên các cột sau khi encoding và thêm tiền tố 'in__'\n",
        "encoded3_column_names = ['in__' + cat for cat in encoder3.categories_[0]]\n",
        "# Tạo DataFrame cho các cột đã được One-Hot Encoded\n",
        "encoded3_df = pd.DataFrame(encoded3_columns, columns=encoded3_column_names)\n",
        "# Kết hợp DataFrame ban đầu với các cột mới\n",
        "anno_df = pd.concat([anno_df, encoded3_df], axis=1)\n",
        "display(anno_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRWmO69nOsph"
      },
      "outputs": [],
      "source": [
        "def prepare_train_predict_data(main_df, annotation_df):\n",
        "    # Tạo bản sao của main_df\n",
        "    train_data = main_df.copy()\n",
        "\n",
        "    # Lấy danh sách username từ các DataFrame\n",
        "    main_usernames = train_data['username']\n",
        "    annotation_usernames = annotation_df['username']\n",
        "\n",
        "    # Tìm các username có trong annotation_df nhưng không có trong main_df\n",
        "    missing_usernames = annotation_usernames[~annotation_usernames.isin(main_usernames)]\n",
        "\n",
        "    # Lọc các hàng trong annotation_df với các username thuộc missing_usernames\n",
        "    filtered_data = annotation_df[annotation_df['username'].isin(missing_usernames)]\n",
        "\n",
        "    # Lấy danh sách username duy nhất từ filtered_data\n",
        "    unique_usernames = filtered_data['username'].unique()\n",
        "\n",
        "    # Tạo DataFrame dự đoán\n",
        "    predict_data = pd.DataFrame(unique_usernames, columns=['username'])\n",
        "\n",
        "    # Cột dự đoán được lấy từ cột thứ hai trong main_df\n",
        "    target_column = main_df.columns[1]\n",
        "\n",
        "    # Đổi tên cột trong train_data theo từ điển rename_dict\n",
        "    train_data.rename(columns=rename_dict, inplace=True)\n",
        "\n",
        "    # Tóm tắt thông tin từ annotation_df theo username\n",
        "    annotation_summary = annotation_df.groupby('username').first().reset_index()\n",
        "\n",
        "    # Ghép dữ liệu từ annotation_summary vào train_data và predict_data\n",
        "    train_data = pd.merge(train_data, annotation_summary, on='username', how='left')\n",
        "    predict_data = pd.merge(predict_data, annotation_summary, on='username', how='left')\n",
        "\n",
        "    # Các cột cần loại bỏ khỏi dữ liệu\n",
        "    columns_to_remove = ['assignment_id', 'problem_id', 'is_final', 'status',\n",
        "                         'pre_score', 'coefficient', 'language_id',\n",
        "                         'created_at', 'updated_at', 'judgement', 'level',\n",
        "                         'submission_date','submission_week','submission_day']\n",
        "\n",
        "    # Loại bỏ các cột không cần thiết\n",
        "    train_data.drop(columns=columns_to_remove, inplace=True)\n",
        "    predict_data.drop(columns=columns_to_remove, inplace=True)\n",
        "\n",
        "    # Loại bỏ các hàng có giá trị null trong cột mục tiêu\n",
        "    train_data.dropna(subset=[target_column], inplace=True)\n",
        "\n",
        "    return train_data, predict_data\n",
        "\n",
        "\n",
        "train_df_TH, predict_df_TH = prepare_train_predict_data(df_th, anno_df)\n",
        "train_df_QT, predict_df_QT = prepare_train_predict_data(df_qt, anno_df)\n",
        "train_df_CK, predict_df_CK = prepare_train_predict_data(df_ck, anno_df)\n",
        "train_df_TL, predict_df_TL = prepare_train_predict_data(df_tbtl, anno_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KDaFJOKBPHV_"
      },
      "outputs": [],
      "source": [
        "after_process_dir = \"/content/drive/MyDrive/dataset/after_process\"\n",
        "\n",
        "#Save to CSV\n",
        "train_df_TH.to_csv(os.path.join(after_process_dir,'train_df_TH.csv'), index=False)\n",
        "train_df_QT.to_csv(os.path.join(after_process_dir,'train_df_QT.csv'), index=False)\n",
        "train_df_CK.to_csv(os.path.join(after_process_dir,'train_df_CK.csv'), index=False)\n",
        "train_df_TL.to_csv(os.path.join(after_process_dir,'train_df_TL.csv'), index=False)\n",
        "\n",
        "predict_df_TH.to_csv(os.path.join(after_process_dir,'predict_df_TH.csv'), index=False)\n",
        "predict_df_QT.to_csv(os.path.join(after_process_dir,'predict_df_QT.csv'), index=False)\n",
        "predict_df_CK.to_csv(os.path.join(after_process_dir,'predict_df_CK.csv'), index=False)\n",
        "predict_df_TL.to_csv(os.path.join(after_process_dir,'predict_df_TL.csv'), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSjSWqpUxdM3"
      },
      "source": [
        "# Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlDVOySIxniB"
      },
      "source": [
        "##1. Spliting data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "mY37rY5JxfjV"
      },
      "outputs": [],
      "source": [
        "X_QT = train_df_QT.drop(columns=[train_df_QT.columns[1], 'username'])\n",
        "y_QT = train_df_QT[train_df_QT.columns[1]]\n",
        "\n",
        "X_TH = train_df_TH.drop(columns=[train_df_TH.columns[1], 'username'])\n",
        "y_TH = train_df_TH[train_df_TH.columns[1]]\n",
        "\n",
        "X_CK = train_df_CK.drop(columns=[train_df_CK.columns[1], 'username'])\n",
        "y_CK = train_df_CK[train_df_CK.columns[1]]\n",
        "\n",
        "X_TL = train_df_TL.drop(columns=[train_df_TL.columns[1], 'username'])\n",
        "y_TL = train_df_TL[train_df_TL.columns[1]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_QT = y_QT.replace('\\xa0', np.nan)  # Thay '\\xa0' bằng NaN\n",
        "y_QT = y_QT.fillna(0)  # Chuyển đổi kiểu dữ liệu về float\n",
        "y_QT = y_QT.astype(float)  # Chuyển đổi kiểu dữ liệu về float\n",
        "\n",
        "y_TH = y_TH.replace('\\xa0', np.nan)  # Thay '\\xa0' bằng NaN\n",
        "y_TH = y_TH.fillna(0)  # Chuyển đổi kiểu dữ liệu về float\n",
        "y_TH = y_TH.astype(float)  # Chuyển đổi kiểu dữ liệu về float\n",
        "\n",
        "y_CK = y_CK.astype(float)\n",
        "y_TL = y_TL.astype(float)\n",
        "\n",
        "print(y_QT.unique())  # Hiển thị các giá trị duy nhất trong cột nhãn\n",
        "print(y_TH.unique())  # Hiển thị các giá trị duy nhất trong cột nhãn\n",
        "print(y_CK.unique())  # Hiển thị các giá trị duy nhất trong cột nhãn\n",
        "print(y_TL.unique())  # Hiển thị các giá trị duy nhất trong cột nhãn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFEa3D8vN01I",
        "outputId": "d26d3e8d-0a6c-4a64-add2-76c0f074f7ec"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 7.5  7.   9.  10.   8.   9.5  6.5  8.5  6.   4.5  5.   1.5  5.5  0.\n",
            "  1.   2.5  2.   3.5  4.   3. ]\n",
            "[ 5.   8.5  7.  10.   6.   7.5  8.   5.5  9.   6.5  9.5  4.5  4.   2.5\n",
            "  3.5  1.   1.5  2.   0.5  3.   0. ]\n",
            "[ 5.5  6.5  4.5  5.   4.   8.   7.   6.   3.5  9.   7.5  8.5  3.  10.\n",
            "  0.   9.5  2.   1.   2.5  0.5  1.5]\n",
            "[7.24 8.11 7.3  8.63 8.2  7.5  6.42 7.23 7.34 8.59 7.41 8.8  8.01 8.6\n",
            " 7.62 7.02 8.19 9.04 8.41 8.7  8.18 8.42 8.76 7.61 8.58 8.3  8.29 8.02\n",
            " 8.32 6.6  8.86 7.89 9.13 7.28 7.97 7.56 8.71 8.5  7.93 7.81 6.77 7.64\n",
            " 7.6  7.65 6.81 6.27 8.87 8.66 8.75 9.28 8.15 7.96 6.67 8.93 6.87 9.2\n",
            " 8.34 7.83 9.   8.72 8.54 7.31 8.84 7.11 7.38 6.41 8.51 6.89 8.17 6.93\n",
            " 9.07 8.53 7.17 7.7  5.89 8.43 7.21 8.65 8.94 7.82 6.61 6.43 2.52 8.1\n",
            " 6.26 8.31 8.82 6.37 8.67 8.79 7.74 8.33 6.82 9.19 6.06 6.57 7.91 6.08\n",
            " 8.99 7.78 7.66 7.19 8.44 8.69 6.46 7.25 7.48 8.52 7.08 8.06 7.54 8.\n",
            " 7.59 7.22 8.4  7.33 7.49 6.68 7.8  8.07 8.38 8.12 7.09 7.44 6.09 7.51\n",
            " 8.83 8.23 8.85 9.59 8.14 9.53 7.42 7.86 7.63 9.16 8.24 7.94 7.73 6.98\n",
            " 8.35 6.34 8.56 8.37 7.72 6.58 7.07 8.39 7.26 6.95 8.09 7.92 7.67 8.73\n",
            " 7.39 7.84 6.65 7.68 7.76 7.71 6.23 6.49 7.14 8.13 7.69 7.45 9.06 8.74\n",
            " 6.66 7.43 6.25 8.04 6.38 8.27 7.79 7.1  8.03 9.29 6.84 2.56 9.15 8.61\n",
            " 8.28 6.79 8.97 7.16 8.64 6.76 9.63 7.12 6.18 9.02 8.46 7.04 7.46 7.77\n",
            " 9.17 8.81 9.45 7.35 7.95 8.62 6.63 6.71 7.15 8.91 9.1  7.05 6.88 7.06\n",
            " 6.15 7.4  7.87 7.75 6.31 8.49 7.13 6.33 7.03 6.69 7.57 6.56 6.   8.57\n",
            " 7.88 6.91 7.32 6.51 8.55 5.6  8.47 7.9  9.35 6.48 6.92 6.85 6.13 8.16\n",
            " 7.01 9.4  8.78 6.17 9.39 9.37 7.52 9.3  9.47 7.85 8.21 7.58 8.22 9.08\n",
            " 7.   9.52 7.55 6.22 6.83 3.2  9.05 5.92 6.59 7.99 7.18 7.2  6.53 5.77\n",
            " 8.36 9.14 9.61 9.21 6.21 6.16 8.26 6.75 7.47 2.91 7.98 8.88 8.89 9.03\n",
            " 8.08 5.8  2.7  9.09 8.48 6.24 6.9  6.7  6.8  8.77 6.19 9.24 6.97 5.94\n",
            " 6.86]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "cHluMPgZxmc5"
      },
      "outputs": [],
      "source": [
        "class WeightedVotingRegressor(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, models, weights):\n",
        "        self.models = models\n",
        "        self.weights = weights\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = np.array([model.predict(X) for model in self.models])\n",
        "        weighted_predictions = np.average(predictions, axis=0, weights=self.weights)\n",
        "        return weighted_predictions\n",
        "\n",
        "def search_model(X, y, random_seed, models):\n",
        "    best_models = []\n",
        "    i = 0\n",
        "    for name, model, params in models:\n",
        "        pipeline = Pipeline([\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('regressor', model)\n",
        "        ])\n",
        "\n",
        "        param_grid = {\n",
        "            'scaler': [StandardScaler(), MinMaxScaler(), None]\n",
        "        }\n",
        "        param_grid.update(params)\n",
        "        kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
        "        grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='r2', n_jobs=12, verbose = 1)\n",
        "        grid_search.fit(X, y)\n",
        "\n",
        "        cv_scores = cross_val_score(grid_search.best_estimator_, X, y, cv=kf, scoring='r2')\n",
        "        mean_cv_score = np.mean(cv_scores)\n",
        "\n",
        "        i += 1\n",
        "        print(f\"#{i} Model: {name}\")\n",
        "        print(f\"Best parameters: {grid_search.best_params_}\")\n",
        "        print(f\"Mean cross-validation score: {mean_cv_score}\")\n",
        "        best = grid_search.best_estimator_\n",
        "        best_models.append(best)\n",
        "        print('-' * 30)\n",
        "\n",
        "    return best_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rUP4WSpyE1J"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "        #1\n",
        "        ('linear', LinearRegression(), {\n",
        "        }),\n",
        "        #2\n",
        "        ('ridge', Ridge(), {\n",
        "            'regressor__alpha': [0.5, 1, 1.5, 2, 2.5, 3, 4, 5]\n",
        "        }),\n",
        "        #3\n",
        "        ('lasso', Lasso(max_iter=5000), {\n",
        "            'regressor__alpha':  [0.2, 0.4, 0.6, 0.8, 1]\n",
        "        }),\n",
        "        #4\n",
        "        ('elastic_net', ElasticNet(max_iter=5000), {\n",
        "            'regressor__alpha': [0.1, 0.3, 0.5, 1, 1.5, 2, 2.5, 3],\n",
        "            'regressor__l1_ratio': [0.2, 0.4, 0.6, 0.8, 1]\n",
        "        }),\n",
        "        #5\n",
        "        ('svr', SVR(), {\n",
        "            'regressor__C': [1.0, 2.0, 3.0, 4.0, 5.0, 6.0 ,7.0],\n",
        "            'regressor__kernel': ['rbf'],\n",
        "            'regressor__epsilon': [0.2, 0.4, 0.6, 0.8, 1]\n",
        "        }),\n",
        "        # #6\n",
        "        ('random_forest', RandomForestRegressor(random_state=42\n",
        "            'regressor__n_estimators': [50, 70, 100],\n",
        "            'regressor__max_depth': [None, 3, 5, 7, 10]\n",
        "        }),\n",
        "        #7\n",
        "        ('knn_regressor', KNeighborsRegressor(), {\n",
        "            'regressor__n_neighbors': [3, 5, 10],\n",
        "            'regressor__weights': ['uniform', 'distance']\n",
        "        }),\n",
        "        #8\n",
        "        ('adaboost', AdaBoostRegressor(random_state=42), {\n",
        "            'regressor__n_estimators': [10, 30, 50, 100, 200, 300],\n",
        "            'regressor__learning_rate': [0.01, 0.03, 0.1]\n",
        "        }),\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUJPL8rNyVgo",
        "collapsed": true,
        "outputId": "918ad4d3-546b-4225-f083-ec13aacf2c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "#1 Model: linear\n",
            "Best parameters: {'scaler': None}\n",
            "Mean cross-validation score: 0.2659576552510249\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "#2 Model: ridge\n",
            "Best parameters: {'regressor__alpha': 2.5, 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.3281923489812457\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "#3 Model: lasso\n",
            "Best parameters: {'regressor__alpha': 0.2, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.18037724151464468\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "#4 Model: elastic_net\n",
            "Best parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.4, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.3221879893848848\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 105 candidates, totalling 525 fits\n",
            "#5 Model: svr\n",
            "Best parameters: {'regressor__C': 5.0, 'regressor__epsilon': 0.4, 'regressor__kernel': 'rbf', 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.36748824553811177\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
            "#6 Model: random_forest\n",
            "Best parameters: {'regressor__max_depth': None, 'regressor__n_estimators': 70, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.3708048252099124\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "#7 Model: knn_regressor\n",
            "Best parameters: {'regressor__n_neighbors': 10, 'regressor__weights': 'distance', 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.36557047474574833\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "#8 Model: adaboost\n",
            "Best parameters: {'regressor__learning_rate': 0.1, 'regressor__n_estimators': 30, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.20173113692785302\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "best_models_QT = search_model(X_QT, y_QT, random_seed=42, models=models)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_TH = search_model(X_TH, y_TH, random_seed=42, models=models)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QKl_UaWYRAg",
        "outputId": "9576b807-2053-45e6-d080-806b42c94589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "#1 Model: linear\n",
            "Best parameters: {'scaler': None}\n",
            "Mean cross-validation score: 0.39124507016540383\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "#2 Model: ridge\n",
            "Best parameters: {'regressor__alpha': 1, 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.4210451853910106\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "#3 Model: lasso\n",
            "Best parameters: {'regressor__alpha': 0.2, 'scaler': None}\n",
            "Mean cross-validation score: 0.2844713542853632\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "#4 Model: elastic_net\n",
            "Best parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.2, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.404027889418204\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 105 candidates, totalling 525 fits\n",
            "#5 Model: svr\n",
            "Best parameters: {'regressor__C': 6.0, 'regressor__epsilon': 0.8, 'regressor__kernel': 'rbf', 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.4775999751962865\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
            "#6 Model: random_forest\n",
            "Best parameters: {'regressor__max_depth': 10, 'regressor__n_estimators': 50, 'scaler': None}\n",
            "Mean cross-validation score: 0.43838028605057777\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "#7 Model: knn_regressor\n",
            "Best parameters: {'regressor__n_neighbors': 10, 'regressor__weights': 'distance', 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.37557900263418853\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "#8 Model: adaboost\n",
            "Best parameters: {'regressor__learning_rate': 0.03, 'regressor__n_estimators': 300, 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.3315814296340639\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_CK = search_model(X_CK, y_CK, random_seed=42, models=models)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "yuKKNDP4YSKE",
        "outputId": "1189f398-28fa-4ab9-8ebb-18cbc9b8126c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-de8b55b509e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_models_CK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_CK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_CK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-01bbaad8f6fb>\u001b[0m in \u001b[0;36msearch_model\u001b[0;34m(X, y, random_seed, models)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mcv_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1569\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1570\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    967\u001b[0m                     )\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 969\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    970\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    971\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m                 (self._jobs[0].get_status(\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models_TL = search_model(X_TL, y_TL, random_seed=42, models=models)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdaZ6KoDYTT4",
        "outputId": "0462eca6-f4ff-4376-fed8-b370e0e7d686"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
            "#1 Model: linear\n",
            "Best parameters: {'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.11608098348798779\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "#2 Model: ridge\n",
            "Best parameters: {'regressor__alpha': 5, 'scaler': None}\n",
            "Mean cross-validation score: 0.19482610322520366\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
            "#3 Model: lasso\n",
            "Best parameters: {'regressor__alpha': 0.2, 'scaler': None}\n",
            "Mean cross-validation score: 0.10776984233018791\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
            "#4 Model: elastic_net\n",
            "Best parameters: {'regressor__alpha': 0.1, 'regressor__l1_ratio': 0.2, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.14924283363990112\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 105 candidates, totalling 525 fits\n",
            "#5 Model: svr\n",
            "Best parameters: {'regressor__C': 2.0, 'regressor__epsilon': 0.4, 'regressor__kernel': 'rbf', 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.21784618820730164\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
            "#6 Model: random_forest\n",
            "Best parameters: {'regressor__max_depth': None, 'regressor__n_estimators': 100, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.11305008136540455\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "#7 Model: knn_regressor\n",
            "Best parameters: {'regressor__n_neighbors': 10, 'regressor__weights': 'distance', 'scaler': MinMaxScaler()}\n",
            "Mean cross-validation score: 0.1271361364618371\n",
            "------------------------------\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "#8 Model: adaboost\n",
            "Best parameters: {'regressor__learning_rate': 0.01, 'regressor__n_estimators': 10, 'scaler': StandardScaler()}\n",
            "Mean cross-validation score: 0.06262408234767795\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search_model(train_df_QT.drop(columns=[train_df_QT.columns[1], 'mssv_h']), train_df_QT[train_df_QT.columns[1]], 42, models)"
      ],
      "metadata": {
        "id": "r_s2-KUif9xT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "baf612b5-ae97-4de6-a487-b89c9ee9bc42"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['diemqt' 'mssv_h'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-80c46c217cab>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_QT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_QT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mssv_h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_QT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_QT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4857\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4858\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4859\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['diemqt' 'mssv_h'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_QT1 = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
        "                            ('regressor', SVR(C=5.0, epsilon=0.4))])\n",
        "model_QT1.fit(X_QT, y_QT)\n",
        "\n",
        "model_QT2 = Pipeline(steps=[('scaler', StandardScaler()),\n",
        "                 ('regressor', ElasticNet(alpha=0.1, l1_ratio=0.4, max_iter=100000))])\n",
        "model_QT2.fit(X_QT, y_QT)\n",
        "\n",
        "list_model_QT = [model_QT1, model_QT2]\n",
        "list_w_QT = [0.5, 0.5]\n",
        "voting_QT = WeightedVotingRegressor(models=list_model_QT, weights=list_w_QT)"
      ],
      "metadata": {
        "id": "O75ZuzYggDnS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm mô hình và tham số cho dự đoán điểm thực hành"
      ],
      "metadata": {
        "id": "8Ih80DWegErr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_model(train_df_TH.drop(columns=[train_df_TH.columns[1], 'username']), train_df_TH[train_df_TH.columns[1]], 42, models)"
      ],
      "metadata": {
        "id": "m0aokRUwgG0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "0cf013dc-0ee5-4f4a-8274-299cbc3b69ad"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['TH' 'mssv_h'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-2753d0b9a1d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msearch_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df_TH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_TH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mssv_h'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df_TH\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df_TH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123456\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5579\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[0;36m1.0\u001b[0m     \u001b[0;36m0.8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5580\u001b[0m         \"\"\"\n\u001b[0;32m-> 5581\u001b[0;31m         return super().drop(\n\u001b[0m\u001b[1;32m   5582\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5583\u001b[0m             \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4787\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4788\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4857\u001b[0m                 \u001b[0mlabels_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4858\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlabels_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4859\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['TH' 'mssv_h'] not found in axis\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_TH1 = Pipeline(steps=[('scaler', MinMaxScaler()), ('regressor', Ridge(alpha=2.5))])\n",
        "model_TH1.fit(X_TH, y_TH)\n",
        "\n",
        "model_TH2 = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
        "                 ('regressor', SVR(C=7.0, epsilon=0.4))])\n",
        "model_TH2.fit(X_TH, y_TH)\n",
        "\n",
        "list_model_TH = [model_TH1, model_TH2]\n",
        "list_w_TH = [0.5, 0.5]\n",
        "voting_TH = WeightedVotingRegressor(models=list_model_TH, weights=list_w_TH)"
      ],
      "metadata": {
        "id": "gOFUl4AMgO3y"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm mô hình và tham số cho dự đoán điểm cuối kỳ"
      ],
      "metadata": {
        "id": "wZJ3y2wNgQzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_model(train_df_CK.drop(columns=[train_df_CK.columns[1], 'mssv_h']), train_df_CK[train_df_CK.columns[1]], 42, models)"
      ],
      "metadata": {
        "id": "kafqUgq_gP4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_CK1 = Pipeline(steps=[('scaler', MinMaxScaler()), ('regressor', Ridge(alpha=4))])\n",
        "model_CK1.fit(X_CK, y_CK)\n",
        "\n",
        "model_CK2 = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
        "                 ('regressor', SVR(C=3.0, epsilon=0.6))])\n",
        "model_CK2.fit(X_CK, y_CK)\n",
        "\n",
        "list_model_CK = [model_CK1, model_CK2]\n",
        "list_w_CK = [0.5, 0.5]\n",
        "voting_CK = WeightedVotingRegressor(models=list_model_CK, weights=list_w_CK)"
      ],
      "metadata": {
        "id": "-ZipPWhmgUcj"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tìm mô hình và tham số cho dự đoán điểm trung bình tích lũy"
      ],
      "metadata": {
        "id": "ARRm7Ob6gWmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_model(train_df_TL.drop(columns=[train_df_TL.columns[1], 'mssv_h']), train_df_TL[train_df_TL.columns[1]], 42, models)"
      ],
      "metadata": {
        "id": "KuQn5RI7gZEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_TL1 = Pipeline(steps=[('scaler', MinMaxScaler()), ('regressor', Ridge(alpha=5))])\n",
        "model_TL1.fit(X_TL, y_TL)\n",
        "\n",
        "model_TL2 = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
        "                 ('regressor', SVR(C=2.0, epsilon=0.4))])\n",
        "model_TL2.fit(X_TL, y_TL)\n",
        "\n",
        "list_model_TL = [model_TL1, model_TL2]\n",
        "list_w_TL = [0.5, 0.5]\n",
        "voting_TL = WeightedVotingRegressor(models=list_model_TL, weights=list_w_TL)"
      ],
      "metadata": {
        "id": "56sMSLO2gbgL"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_submit(model, df, desc, predict_col):\n",
        "    tdf = df.copy()\n",
        "    predicted_target = model.predict(tdf.drop(columns=['username']))\n",
        "    tdf['target'] = predicted_target\n",
        "    tdf['target'] = tdf['target'].apply(lambda x: min(max(x, 0), 10))\n",
        "    output_df = tdf[['username', 'target']]\n",
        "    output_df.to_csv(f'out_{predict_col}_{desc}.csv', index=False, header=False)\n",
        "\n",
        "predict_submit(voting_QT, predict_df_QT, 'final', 'QT')\n",
        "\n",
        "predict_submit(voting_TH, predict_df_QT, 'final', 'TH')\n",
        "\n",
        "predict_submit(voting_CK, predict_df_CK, 'final', 'CK')\n",
        "\n",
        "predict_submit(voting_TL, predict_df_TL, 'final', 'TL')"
      ],
      "metadata": {
        "id": "z6vNZv5pII8t"
      },
      "execution_count": 59,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}